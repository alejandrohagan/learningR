{
  "hash": "97eae2fd0ada0332f319e1a71f35a2d6",
  "result": {
    "engine": "knitr",
    "markdown": "# How to save things on Git\n\n-   You can either save on a local site or you can push to a version sharing repository.\n-   Critical that you get familiar with version sharing site\n\nhow to connect to github\n\nwhile all this may seem to new, quite honestly its because we have never been told good versioning and collaboration practices so we are reliant on saving to a LAN system, amending the name with versioning control\n\ncreate a new github repsository in github\n\ngo to global settings (not repository settings), go to develrop settings and click personal access tokens\n\ngenerate new token, copy (consider saving as you can only see it once)\n\nsave token with\ncredentials::set_github_pat()\n\ncheck everything with\ngitcreds_get()\n\ngit config --global credential.helper 'cache --timeout=10000000'\n\nusethis::git_branch_default()\n\ncheck local branch\n\ngert::git_remote_ls()\n\nget information\n\nresources\n\nhttps://rfortherestofus.com/2021/02/how-to-use-git-github-with-r/\n\n{r} usethis::use_git_remote(\"origin\",url=NULL,overwrite=TRUE) usethis::use_github() usethis::gh_token_help()\n\nusethis::use_git_remote(name = \"origin\",url = \"https://github.com/alejandrohagan/learningR.git\",overwrite=TRUE)\n\ngitcreds::gitcreds_set(url = \"https://github.com/alejandrohagan/learningR.git\")\n\nusethis::use_github() usethis::git_default_branch()\n\ngh::gh_whoami()\n\nusethis::git_remotes()\n\nusethis::pr_push()\n\nusethis::pr_fetch()\n\nusethis::pr_pull()\n\nusethis::pr_init(branch = \"main\")\n\ngit config pull.rebase false\n\nusethis::use_git_remote(name = \"origin\",url = \"https://github.com/alejandrohagan/learningR.git\",overwrite=TRUE))\n\n• To create a personal access token, call `create_github_token()` • To store a token for current and future use, call `gitcreds::gitcreds_set()`\n\n5 steps to change GitHub default branch from master to main \\| R-bloggers\n\nDon't Lose your HEAD over Default Branches \\| R-bloggers\n\nGit: Moving from Master to Main \\| R-bloggers\n\npush & committ and commenting\n\nHow to manipulate & tidy data\n\n##how to import data----------\n\nread.csv()\n\nread_csv()\n\nfread()\n\n##how to change column types----\n\nhow to create data\n\nseq() runif() sample(data,# of times, replace,) c() data.frame()\n\nhow to create data with basic loops / repitition\n\ntypes of data\n\nvector data.frame list\n\nsome base R basics that will be helpful to you as you read the forums\n\nhow to import files\n\nby folder\n\nby website\n\nexcel spreadsheet\n\npowerbi model\n\nhow to find files by their type\n\nhow to append files together\n\nhow to automate file importation\n\nfile column names\n\nhow to change column names\n\nstatically\n\ndynamically\n\nbest practices when naming columns\n\nhow to change column types\n\nstatically\n\ndynamically\n\nhow to check data structure\n\n-unique\n\nhow to clean data\n\nhow to shape data\n\nhow to subset data\n\nfilter\n\ndynamic\n\nstatic\n\nselect\n\ndynamic\n\nstatic\n\ngrouby\n\nsummarize\n\nmutate\n\nfill / blanks/ replace values\n\nrecode\n\npivot / unpivot\n\nmerge\n\niterate\n\napply a single function (single input or multiple inputs) to every/ some/ based on criteria column and get its outputs into a data frame (to be accessed)\n\napply a single function with multiple inputs\n\napply a functions to nested data frames\n\nexplatory analysis\n\nstart with variance analysis\n\nhow to extract information out of a table\n\nfor (i in range){\n\ndo something }\n\nbasic framework 1. is to define the vector that you want as an output and its size with vector(\"type\",vectorsize) 2. assign that vector names with names() so that data has headings 3. create for (i in range) 4. define the task it will do individually to thedataset 4. assign that to the output vector\n\ntips & tricks\n\ncheck the task individually against a single element to ensure it works\n\nyou can extract other elements (typically row / column names) using other techniques (names()) and assign to output (doesn't need to be in the loop) -use seq_along(), ncol(), \\[\\[\\]\\] to define parameters and extract elements\n\n{r loop_example, message=FALSE, warning=FALSE} output \\<- vector(\"double\",ncol(mtcars)) #assigns the output vector\n\ncols_names \\<- names(mtcars) \\# assigns names of the dataframe to variable names(output) \\<- cols_names \\# assigns the names\n\nfor (i in cols_names) { \\# sometimes useful to use seq_along() here as well\n\noutput\\[i\\] \\<- mean(mtcars\\[\\[i\\]\\]) \\# the double brackets ensures we only take out one item, this needs to be adjusted if two iems are expected, change the vector to a list\n\n}\n\noutput\n\n### Categorical Variables\n\nIn general you will need to distinguish betwen your character values as either straight character or categorical with levels\n\nThis becomes critical as you look to create categories and relationships in your data\n\nforecats is the gotopackage in particular:\n\nrename\n\nrecode() to change values in column\n\nrecode(col,newvalue=oldvalue)\n\nreorder\n\nfct_relevel\n\nfct_relevel(col,level1,level2,etc)\n\nfct_reorder(col,col_to_be_reorderby,function)\n\n3)group variables into another group\n\ncase_when()\n\n-typically used in combination with mutate() -can reference multiple conditions\n\ncase_when(col1==var1 \\~ val1, col1==var2 & col3==var3 \\~ var 2, is.na(col1) \\~ \"missingvalue\", TRUE \\~ \"defaultvalue )\\` cut()\n\n##purr\n\n{ } is used to stop a data frame from passing into as first agurmen\n\n. is a place holder for the data frame\n\n{r } list.len=3 str(mpg,list.len=3)\n\nstr(mpg) listviewer::jsonedit(mpg)\n\n#patchwork\n\ncan organize with easy convention +,/,\\| is two charts on top and one chart beneath\n\nbut can also supplement with additional functions\n\nplot_layout can also arrnage by rows\n\nplot_layout(nrow = 3, byrow = FALSE) arguments: width= changes the graphs relative width size, when given as a numeric c(2,1) then the first columsn graphs are twice as large as the second columns height= changes the graphs reltive row heigh, ncol= numeric, changes number of columsn guides=\"collect\" to remove duplicate guides theme(legend.position='bottom') moves the legend position\n\nguide_area() to create area that guides=collect move towards\n\nhttps://patchwork.data-imaginist.com/reference/plot_layout.html\n\nplot_annotation() to add annotation title = 'The surprising story about mtcars' tag_levels = 'I' or \"A\" or \"1\" to set tag on each plot caption=\"Text\" theme = theme(plot.title = element_text(size = 16))\n\nuse the below to add a blank text tile next to a plot grid::textGrob('Some really important text') or a table gridExtra::tableGrob(mtcars$$1:10, c('mpg', 'disp')$$)\n\nplot_spacer() inserts an empty plot\n\ninset_element() to insert a sub graph ontop of a new one\n\nleft = 0.6, bottom = 0.6, right = 1, top = 1 align_to = 'full\n\nhelpful tips:\n\nWhen creating a patchwork, the resulting object remain a ggplot object referencing the last added plot. This means that you can continue to add objects such as geoms, scales, etc. to it as you would a normal ggplot:When creating a patchwork, the resulting object remain a ggplot object referencing the last added plot. This means that you can continue to add objects such as geoms, scales, etc. to it as you would a normal ggplot:geom_jitter(aes(gear, disp))\n\nOften, especially when it comes to theming, you want to modify everything at once. patchwork provides two additional operators that facilitates this. & will add the element to all subplots in the patchwork, and \\* will add the element to all the subplots in the current nesting level. As with \\| and /, be aware that operator precedence must be kept in mind.\n\nstr_replace_all //s+ = all white spaces\n\nhow to write tables\n\nfont 1. Numerical data is right-aligned 2. Textual data is left-aligned 3. Headers are aligned with their data 3½. Don't use center alignment.\n\n#visual guide \\## axis title - axis title always all caps - align top y axis or left axis - color to match axis color \\## graph title left alignment\n\nAcross(), if_any,if_all\n\nsummarize/mutuate/pivot_longer/pivot_wider\n\nacross // character based\n\nstarts_with\n\nends_with\n\ncontains\n\nmatches\n\nnum_range()\n\nlast_col\n\nwhere()// with a function that has bolean condition eg. is.numeric\n\nused to select columns by name, position or type (requires where() wrapp)\n\nc(column names), position or type (where)\n\nfunction, or list( function1=function(), function2=function())\n\n{} is used to refenence preivously declared variables in the glue package or in functions that rerence glue package\n\nsome attributes have sepcial references, such as {.col} to reference a column and {.fn} to refernece a function\n\nused in the .names argument of across\n\n`across()` doesn't work with `select()` or `rename()`\n\nmutate, group_by,count,distinct,summarize\n\nfilter is excluded and instead use if_any and if_all with exceltiion of\n\nfilter(across(everything), \\~function)\n\nExamples for filter\n\n-   `if_any()` keeps the rows where the predicate is true for *at least one* selected\n\ncolumn:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nstarwars %>%\n\nfilter(if_any(everything(), ~ !is.na(.x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 87 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   <chr>     <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 C-3PO       167    75 <NA>       gold       yellow         112   none  mascu…\n 3 R2-D2        96    32 <NA>       white, bl… red             33   none  mascu…\n 4 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 5 Leia Or…    150    49 brown      light      brown           19   fema… femin…\n 6 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 7 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n 8 R5-D4        97    32 <NA>       white, red red             NA   none  mascu…\n 9 Biggs D…    183    84 black      light      brown           24   male  mascu…\n10 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n# ℹ 77 more rows\n# ℹ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#   vehicles <list>, starships <list>\n```\n\n\n:::\n:::\n\n\n-   `if_all()` keeps the rows where the predicate is true for *all* selected columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstarwars %>%\n\nfilter(if_all(everything(), ~ !is.na(.x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 29 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   <chr>     <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 3 Leia Or…    150    49 brown      light      brown           19   fema… femin…\n 4 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 5 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n 6 Biggs D…    183    84 black      light      brown           24   male  mascu…\n 7 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n 8 Anakin …    188    84 blond      fair       blue            41.9 male  mascu…\n 9 Chewbac…    228   112 brown      unknown    blue           200   male  mascu…\n10 Han Solo    180    80 brown      fair       brown           29   male  mascu…\n# ℹ 19 more rows\n# ℹ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#   vehicles <list>, starships <list>\n```\n\n\n:::\n:::\n\n\n-   Find all rows where no variable has missing values:\n\n\n\nNeed to investigate rename_with and and itsimpact on select as it appears to be superseded\n\ndplyr/colwise.Rmd at main · tidyverse/dplyr · GitHub\n\nglamour of graphics\n\nalignemtn\n\ntop left aligned to the chart left (plot.titile.position=\"plot\"\n\nadd_count(dim,name=\"text\") %\\>% mutate(colname= glue::glue(\"{col}{text}\")\n\nrotate lebels, either by swapping axis or removing axis all together\n\nremove borders\n\nremove gridlines\n\nleft /right align text to create clean borders\n\nindicate legend in title\n\ngraphing tips and tricks\n\nif you want to plot a subset of the data but show atrend agains the full data, leverage the data argument in the each individual geom (rather that defining this globally) (example below)\n\nR-Ladies Freiburg (English) - Level up your ggplot: Adding labels, arrows and other annotations - YouTube\n\ngeom_curve\n\naes(x,y,xend,yend)\n\narrow=arrow(length=unit(x,\"inch)),\n\nsize\n\ncolr\n\ncurvature(0 is straight line, positive is right hand curve, negative is left hand curve)\n\nggforce package has advanced annotation options\n\ngeom_mark_circle\n\ngeom_mark_rect\n\ngeom_mark_hull\n\ngeom_mark_elipse\\`\n\naes(label,filter,description)\n\nexpand\n\nlabel.lineheight\n\nlabel.fontsize\n\nshow.legend\n\nggforce() package\n\nwith_blur() can blur the geoms (ten need to seperately map the geoms that you do want to show\n\nneed to warp the geom_jitter comand in with_blur\n\nwith_blur(\n\ngeom_jitter(),\n\nsigma = unit(#,\"mm\") #blur impact\n\nfacet_zoom()# takes a larger dataset and then adds in a zoomed up graph\n\nfacet_zoom(axis =argument==filterar_gument)\n\nfacet_zoom(x=country==\"spain\")\n\nfacet_zoom(y=length \\<20)\n\n\nProgramming with dplyr • dplyr (tidyverse.org)\n\nArgument type: tidy-select --- dplyr_tidy_select • dplyr (tidyverse.org)\n\nTidy evaluation is not all-or-nothing, it encompasses a wide range of features and techniques. Here are a few techniques that are easy to pick up in your workflow:\n\nPassing expressions through {{ and ....\n\nPassing column names to .data\\[\\[ and one_of().\n\nAll these techniques make it possible to reuse existing comp\n\nWhen creating forumlas how to referece to names?\n\nSTart with fixed names (only if you are sure it wont change) and try wrapping that around a test to ensur eit exists\n\nduoble currly braces {{}}\n\nWhen you want to reference a data variable from an env. variable in function, you pass the dataframe to the function then wrap the data var with {{var}} in order pull it from the env frame (instead of saying data\\$x)\n\nwhere() for search paramters\n\n.data\\[\\[var\\]\\]\n\nif you env variable is a character frame that you must use .data\\[\\[var\\]\\]\n\nall_of or any_of for character vectors for search praramters\n\n<!-- -->\n\ncompute_bmi \\<- function(data) { if (!all(c(\"mass\", \"height\") %in% names(data))) { stop(\"`data` must contain `mass` and `height` columns\") }\n\ndata %\\>% transmute(bmi = mass / height\\^2) }\n\nhow to use as nmaes\n\n\"mean\\_{{var}}\" := mean({{var}})\n\nOpen questions\n\nwhen do you sue data and when do use .data (okay answer apparently when you use \n... you start other variables with \".\" eg. .data to avoid conflictino ix \\| Tidyverse design guide\n\n)\n\nf you want the user to provide a set of data-variables that are then transformed, use across():\n\nmy_summarise \\<- function(data, summary_vars) { data %\\>% summarise(across({{ summary_vars }}, \\~ mean(., na.rm = TRUE))) } starwars %\\>% group_by(species) %\\>% my_summarise(c(mass, height)) #\\> \\# A tibble: 38 × 3 #\\> species mass height #\\> <chr> <dbl> <dbl> #\\> 1 Aleena 15 79 #\\> 2 Besalisk 102 198 #\\> 3 Cerean 82 198 #\\> 4 Chagrian NaN 196 #\\> \\# ... with 34 more rows\n\nYou can use this same idea for multiple sets of input data-variables:\n\nmy_summarise \\<- function(data, group_var, summarise_var) { data %\\>% group_by(across({{ group_var }})) %\\>% summarise(across({{ summarise_var }}, mean)) }\n\nUse the .names argument to across() to control the names of the output.\n\nmy_summarise \\<- function(data, group_var, summarise_var) { data %\\>% group_by(across({{ group_var }})) %\\>% summarise(across({{ summarise_var }}, mean, .names = \"mean\\_{.col}\")) }\n\nAction versb to know how to use\n\nArgument type: tidy-select --- dplyr_tidy_select • dplyr (tidyverse.org)\n\neverything(): Matches all variables.\n\nlast_col(): Select last variable, possibly with an offset.\n\nThese helpers select variables by matching patterns in their names:\n\nstarts_with(): Starts with a prefix.\n\nends_with(): Ends with a suffix.\n\ncontains(): Contains a literal string.\n\nmatches(): Matches a regular expression.\n\nnum_range(): Matches a numerical range like x01, x02, x03.\n\nThese helpers select variables from a character vector:\n\nall_of(): Matches variable names in a character vector. All names must be present, otherwise an out-of-bounds error is thrown.\n\nany_of(): Same as all_of(), except that no error is thrown for names that don't exist.\n\nThis helper selects variables with a function:\n\nwhere(): Applies a function to all variables and selects those for which the function returns TRUE.\n\narrange(), count(), filter(), group_by(), mutate(), and summarise() use data masking so that you can use data variables as if they were variables in the environment (i.e. you write my_variable not df\\$myvariable).\n\nacross(), relocate(), rename(), select(), and pull()\n\nrowwise()\n\ncolwise()\n\nTricks\n\nmean in summarize will give you the portion of that variable per the group\n\npurr\n\nresources\n\n9 Basic map functions \\| Functional Programming (stanford.edu)\n\nMap and Nested Lists \\| R-bloggers\n\npattern\n\ntake one element .x\\<-list\\[\\[1\\]\\]\n\ndo the formula based on that element\n\nset_names() without argument sets the names equal to the values\n\nmap returns list, control map outcomes with map alternatives eg. map_df, map_dbl\n\nif function has more than one argument then define a function upfront in global environment and pass the second y argument as explicit command in map \\[follow up how to do this in anonymous way)\n\nmap(1:5,custom_function,y=2)\n\npmap for more than one vector\n\ncan also pass through functions as objects not just data\n\nfuns\\<- list(mean,median,sd)\n\nmap(funs,\\~map_dbl(mtcars,.x))\n\nstart on the inside and then work your way to the outside\n\nwalk similiar ot map but is design for function that you want to run soley for hte side effects\n\nso walk will always return the origional vector eg. walk(.x,.f)=\\> .x whereas map will return map(.x,.f)=\\> .f(.x.\n\nSo why use walk? when you want the formula side effectt (eg saving a picture)\n\naccumulate\n\napplies same function again and again and again\n\napplies function to first argument then takes that result and applies that outcome to second argument\n\neg. accumulate(letters,paste), will produce a prymid of values of all the letters\n\nso accumlate will show all the interim values\n\nreduce will only show the final value\n\nthis is recursive\n\nHowever, if you want pair wise actions 1*1, 2*2, etc then you need map2\n\ntidytext\n\nunnest_tokens basically takes a string and breaks t into characters, words, or others ngrams,\n\nFrom there use typical dplybs to graph, popular geoms are geom_text to plot the words aagainst their proportion.\n\ntypiecal tokenize methodologies use ICI (international components of unicode) which defines word boundaries )\n\nChapter 2 Tokenization \\| Supervised Machine Learning for Text Analysis in R (smltar.com)\n\npackages\n\ntidytext\n\ntokenize\n\nstopwords\n\nSnowballC for stemming\n\nhunspell also for stemming / spell check\n\ntypes of toekn\n\ncharacters\n\nwords,\n\nsentences\n\nlines,\n\nparagraphs\n\nngrams\n\nyou can use tidytext package or tokenize package but here is your pattern\n\ngrab text\n\nadd a dimenion factor (eg. chapter, author, book)\n\nnest the data by the dimension\n\nif data is nested use mutate(map()) pattern to perform transformations\n\nif doing setences or paragraphs you may need to paste() the text and add paragraph breaks \"\\n\" (paragraphs) or space breaks \" \" (sentences)\n\nthen use either tidytext(returns tibble) or tokenizer (returns lists) to do unnesting work\n\nunnest data\n\nanti_join(stop_words)\n\nregex considerations\n\n\\[:alpha:\\] brings in non US lettesr where as \\[a-zA-Z\\] only brings in US letters\n\n? is optional (will match or not)\n\n\\^ starts with\n\n\\$ends with\n\n| or\n\nstop words\n\nstopwords package with snowball, iso and other packages\n\nstemming\n\ncan stem words tree, tree's into single word\n\nhowever also has impact of creating new words to stem by\n\nSnowballC package offers wordStem\n\ntokenizer::tokenize_word_stems\n\nhunspell:hunspell_stem\n\nmore resources\n\nChapter 2 Tokenization \\| Supervised Machine Learning for Text Analysis in R (smltar.com)\n\ntidytext\n\n## tidy evaluation\n\nresources\n\n2 Why and how \\| Tidy evaluation (tidyverse.org)\n\nProgramming with dplyr • dplyr (tidyverse.org)\n\nImplementing tidyselect interfaces • tidyselect (r-lib.org)\n\nTechnical description of tidyselect • tidyselect (r-lib.org)\n\n13 Tidy evaluation basics \\| Functional Programming (stanford.edu)\n\nprinciples\n\ndata masking is when you delay the evaluation of a code so that the code can find relevant columns for computation. th\n\nThis is why you can can do::\n\n{r}\n\n#this will work starwars %\\>% filter( height \\< 200, gender == \"male\" )\n\n#but really the program needs this, reference to dataframe and column starwars\\[starwars$height < 200 & starwars$gender == \"male\", \\]\n\ntechnical term for delaying code is quoting\n\nthis delaying of code evalution can help you when using code but also make things more complicated when writing code\n\nvectoring can occur when either input has 1 or same length of input object to ensure all columns have same length\n\nsome functions can repeat values if recycling completes the length\n\nhowevre other,like tidyverse family don't\n\n!! takes a variable defined outside of function and allows you to use it within a function x\\<-1 function(x) !!x+1, qq_show() allows you to see what is happening\n\n!! works for assiging a variable not a column name or only variable\n\n!! is simliar to := but := is only for left hand side eg setting a name\n\nwhen working with lists you need !!! to pull out each element and pass it through otherwise !! just pass through the list as is also need to use enquos() vs. enquo\n\nsym) is how you quote for column names and !! is how you unquote, however sym() only works for character strings so \"mpg\" vs. mpg\n\nenquo is used for non character strings and then !! is how you unquote them\n\nrlang::qq_show will help show what how !! is being evaluated\n\npattersn\n\nenquo() and !!\n\n:= and !!\n\nenquos() and !!!\n\nhow to use environment character vectors in a function or formula?\n-   use all_of() or any_of() (use ! to negate) [linkhere](https://dplyr.tidyverse.org/articles/programming.html)\n-   you can also suse sym or syms with !!! [link here](https://stackoverflow.com/questions/34487641/dplyr-groupby-on-multiple-columns-using-variable-names)\n\n\nhow to quote a uncharacter argument into a character arugment\n-    dots <- enquos(..., .named = TRUE) will turn a unquoted input into a quosure variable\n-   nm1 <- purrr::map_chr(dots, rlang::as_label) then use this to transform into character vectors which canbe used in functions [linkhere](https://stackoverflow.com/questions/63257632/curly-curly-tidy-evaluation-programming-with-multiple-inputs-and-custom-function)\n\n#PCA\n\npca_rec \\<- recipe(\\~., data = sample_df) %\\>% update_role(daily_miss, new_role = \"id\") %\\>% step_normalize(all_predictors()) %\\>% step_pca(all_predictors())\n\npca_prep \\<- prep(pca_rec)\n\npca_prep\n\ntidied_pca \\<- tidy(pca_prep, 2)\n\ntidied_pca %\\>% filter(component %in% paste0(\"PC\", 1:5)) %\\>% mutate(component = fct_inorder(component)) %\\>% ggplot(aes(value, terms, fill = terms)) + geom_col(show.legend = FALSE) + facet_wrap(\\~component, nrow = 1) + labs(y = NULL)\n\nprincomp with plot(pca_mod, type=\"lines\").\n\n## advanced plotting, contorl over color, shape or alpha------\n\n1)  add column that by attribution (eg. color, shape,alpha)\n2)  use case_when that identifies row attributes and gives the custom formatting\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds_formatting <- diamonds %>% \n  mutate(\ncustom_col= case_when(\n  between(price, 400,2000) ~ 'grey60',\n  price < 5000 ~ \"red\",\n  price < 10000 ~ \"blue\",\n  price < 20000 ~ \"purple\",\n  color ==\"G\" ~ '#AA4465',\n  TRUE ~ \"orange\"),\ncustom_shape=case_when(\n  color ==\"G\" |color==\"E\" ~ 13,\n  TRUE ~ 4)\n  \n)\n```\n:::\n\n\n3)  pass arguments to ggplot mapping the col, shape, alpha to the respective columns\n4)  **must** add `scale_*_identity()` to the plot for this to work\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds_formatting %>% \n  ggplot(aes(price,color,col=custom_col,shape=custom_shape))+\n  geom_point()+\n  scale_color_identity()+\n  scale_shape_identity()\n```\n\n::: {.cell-output-display}\n![](learningR_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n5)  source (https://alberts-newsletter.beehiiv.com/)\\[\\]\n\n#tidyselect verbs\n\ncontains() starts_with() ends_with() 1:10 a:b last_col() -offset=X --offset argument matches() num_range() -needs arguments\n\nbased on character names all_of() any_of()\n\npass a formula to check against each column where() -is.numeric() -is.factor() \\~mean(.x) \\>3.5\n\n### common tasks---\n\napply a function to multiple columns to perform action onto column or new columns - Across() apply a column of arguments, one by one, as input into a function - map() apply two or more column of arguments as simulataneous inputs into a function - map2() apply one column of arguments as input to function, then combine output with new argument - purrr::reduce()\n\napply a function to pairs of columns on a rolling basis (eg. col 1 -2, col 2 - 3, etc) ????\n\n\n::: {.cell}\n\n:::\n\n\n## count\n\ncount very useful function to quickly tabulate data use .drop to show any data that has been filtered out or removed\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n### how to parse out words from a sentence\n\n-   fixed position and fixed seperated but whole word (seperated by consistent seperator\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstring <- c(\"I only want the third word of each sentence\",\n            \"I only need the third word of each setence\",\n            \"I only use the third worsd of each sentence\")\nlibrary(tidyverse)\nstringr::word(string, #vector of strings\n              start=3, #where to start extraction\n              end=3, #where to end extraction\n              sep=\" \")# what seperator to parse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"want\" \"need\" \"use\" \n```\n\n\n:::\n:::\n\n\nstringr::word(string,start=x,end=y,sep=?)\n\nis.element(input,check_strings) -- validates inputs matches at least one in a set\n",
    "supporting": [
      "learningR_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}